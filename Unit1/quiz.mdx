# Quiz 

The best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf) **is to test yourself.** This will help you to find **where you need to reinforce your knowledge**.

### Q1: What is Reinforcement Learning?

<details>
<summary>Solution</summary>

Reinforcement learning is a **framework for solving control tasks (also called decision problems)** by building agents that learn from the environment by interacting with it through trial and error and **receiving rewards (positive or negative) as unique feedback**.

</details>



### Q2: Define the RL Loop

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/rl-loop-ex.jpg" alt="Exercise RL Loop"/>

### At every step:

- Our Agent receives ______ from the environment  
- Based on that ______ the Agent takes an ______  
- Our Agent will move to the right  
- The Environment goes to a ______  
- The Environment gives a ______ to the Agent

**Choices:**

1. **an action a0, action a0, state s0, state s1, reward r1**  
   _Explanation_: Our Agent receives **state s0** from the environment. Based on that **state s0** the Agent takes an **action a0**. Our Agent will move to the right. The Environment goes to a **new state s1**. The Environment gives **a reward r1** to the Agent.

2. **state s0, state s0, action a0, new state s1, reward r1** ✅

3. **a state s0, state s0, action a0, state s1, action a1**  
   _Explanation_: Same as above but ends incorrectly.

---

### Q3: What's the difference between a state and an observation?

**Choices:**

1. **The state is a complete description of the state of the world (there is no hidden information)** ✅  
2. **The state is a partial description of the state**  
3. **The observation is a complete description of the state of the world (there is no hidden information)**  
4. **The observation is a partial description of the state** ✅  
5. **We receive a state when we play with chess environment** ✅  
   - _Explanation_: We have access to the whole chessboard.  
6. **We receive an observation when we play with chess environment**  
   - _Explanation_: Incorrect — we get full info.  
7. **We receive a state when we play with Super Mario Bros**  
   - _Explanation_: Incorrect — we don’t see the full level.  
8. **We receive an observation when we play with Super Mario Bros** ✅  
   - _Explanation_: Only part of the level is visible.

---

### Q4: A task is an instance of a Reinforcement Learning problem. What are the two types of tasks?

**Choices:**

1. **Episodic** ✅  
   - _Explanation_: Has a clear start and end (e.g., a Mario level).  
2. **Recursive**  
3. **Adversarial**  
4. **Continuing** ✅  
   - _Explanation_: No terminal state; runs indefinitely (e.g., stock trading).


### Q5: What is the exploration/exploitation tradeoff?

<details>
<summary>Solution</summary>

In Reinforcement Learning, we need to **balance how much we explore the environment and how much we exploit what we know about the environment**.

- *Exploration* is exploring the environment by **trying random actions in order to find more information about the environment**.

- *Exploitation* is **exploiting known information to maximize the reward**.

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/expexpltradeoff.jpg" alt="Exploration Exploitation Tradeoff" width="100%">

</details>


### Q6: What is a policy?

<details>
<summary>Solution</summary>

- The Policy π **is the brain of our Agent**. It’s the function that tells us what action to take given the state we are in. So it defines the agent’s behavior at a given time.

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_1.jpg" alt="Policy">

</details>


### Q7: What are value-based methods?

<details>
<summary>Solution</summary>

- Value-based methods is one of the main approaches for solving RL problems.
- In Value-based methods, instead of training a policy function, **we train a value function that maps a state to the expected value of being at that state**.



</details>

### Q8: What are policy-based methods?

<details>
<summary>Solution</summary>

- In *Policy-Based Methods*, we learn a **policy function directly**.
- This policy function will **map from each state to the best corresponding action at that state**. Or a **probability distribution over the set of possible actions at that state**.




</details>
